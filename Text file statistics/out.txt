__2_	n: 1	Lines: 12, 
_abc	n: 1	Lines: 12, 
a	n: 6	Lines: 2, 7, 8, 
allowed	n: 2	Lines: 5, 6, 
also	n: 1	Lines: 7, 
an	n: 2	Lines: 1, 2, 
and	n: 2	Lines: 3, 6, 
are	n: 2	Lines: 1, 4, 
as	n: 5	Lines: 1, 2, 6, 7, 
be	n: 5	Lines: 3, 5, 6, 7, 
become	n: 1	Lines: 8, 
being	n: 1	Lines: 3, 
both	n: 1	Lines: 5, 
but	n: 3	Lines: 1, 2, 5, 
can	n: 1	Lines: 3, 
case	n: 2	Lines: 4, 8, 
character	n: 1	Lines: 1, 
clause	n: 1	Lines: 2, 
clear	n: 1	Lines: 9, 
compatibility	n: 1	Lines: 8, 
context	n: 2	Lines: 6, 7, 
determined	n: 1	Lines: 6, 
distinction	n: 1	Lines: 9, 
distinguished	n: 1	Lines: 5, 
e	n: 1	Lines: 9, 
example	n: 1	Lines: 2, 
fdb	n: 1	Lines: 13, 
few	n: 1	Lines: 8, 
foo	n: 1	Lines: 2, 
for	n: 3	Lines: 2, 8, 
forbidden	n: 2	Lines: 3, 7, 
form	n: 2	Lines: 1, 2, 
forward	n: 1	Lines: 8, 
frequently	n: 1	Lines: 2, 
from	n: 2	Lines: 3, 6, 
future	n: 1	Lines: 8, 
g	n: 1	Lines: 9, 
handled	n: 1	Lines: 3, 
have	n: 1	Lines: 1, 
identification	n: 1	Lines: 10, 
identifier	n: 1	Lines: 1, 
identifiers	n: 3	Lines: 3, 6, 7, 
if	n: 2	Lines: 2, 
ig	n: 1	Lines: 2, 
In	n: 7	Lines: 1, 3, 4, 5, 8, 
is	n: 4	Lines: 2, 6, 9, 
Just	n: 1	Lines: 10, 
keyword	n: 3	Lines: 2, 6, 8, 
keywords	n: 2	Lines: 1, 7, 
known	n: 1	Lines: 1, 
languages	n: 2	Lines: 1, 8, 
letters	n: 1	Lines: 2, 
lexer	n: 1	Lines: 7, 
lexical	n: 1	Lines: 1, 
lexically	n: 1	Lines: 2, 
may	n: 5	Lines: 3, 5, 6, 7, 8, 
most	n: 1	Lines: 1, 
namely	n: 1	Lines: 2, 
Non	n: 1	Lines: 7, 
not	n: 1	Lines: 9, 
of	n: 3	Lines: 1, 2, 
or	n: 2	Lines: 2, 6, 
other	n: 1	Lines: 5, 
overlap	n: 1	Lines: 3, 
parsing	n: 1	Lines: 3, 
particularly	n: 1	Lines: 8, 
PL	n: 1	Lines: 9, 
requires	n: 1	Lines: 7, 
reserved	n: 2	Lines: 4, 7, 
same	n: 1	Lines: 2, 
sense	n: 1	Lines: 6, 
sensitive	n: 1	Lines: 7, 
sequence	n: 1	Lines: 2, 
sequences	n: 2	Lines: 1, 6, 
simplifies	n: 1	Lines: 3, 
simply	n: 1	Lines: 10, 
some	n: 1	Lines: 1, 
stropping	n: 1	Lines: 6, 
such	n: 1	Lines: 6, 
test	n: 1	Lines: 10, 
the	n: 4	Lines: 1, 2, 9, 10, 
these	n: 1	Lines: 3, 
they	n: 2	Lines: 4, 5, 
This	n: 1	Lines: 3, 
to	n: 1	Lines: 10, 
tokenization	n: 1	Lines: 3, 
various	n: 1	Lines: 3, 
via	n: 1	Lines: 6, 
ways	n: 2	Lines: 3, 5, 
which	n: 4	Lines: 3, 4, 6, 7, 
word	n: 1	Lines: 8, 
words	n: 2	Lines: 4, 7, 
